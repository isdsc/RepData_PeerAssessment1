---
title: "Reproducible Research: Peer Assessment 1"
output: 
  html_document:
    keep_md: true
---


## Loading and preprocessing the data

Before analyzing the data, we need to load the data into R. The assignment
instructions inform us that the input data contains three columns: `steps`,
`date`, and `interval`. Furthermore the instructions indicate that the dataset
is stored in a comma-separated-value (CSV) file and that there are a total of
17,568 observations in it. The input data is in the file `activity.zip`. From
the extension, we will assume that it is in compressed format.

Just to make sure that our assumption is correct and to get a sense of the
input data, we will take a quick peek at a few records from the input file.
For this task we could use external programs like `head` or `tail`. However,
while these are usually available on *nix systems, they are not available on
standard Windows systems (unless added on later by Cygwin or msys etc.).

To remain platform-agnostic, instead of using `read.csv()` from the base R
system we will use the `fread()` function from the `data.table` package. Also,
the data loading code assumes that open source 7-Zip archive management
software is available in the in the search path of the OS.

```{r}
# Set the working directory and get the contents of the .zip file
setwd("~/Coursera/Data Science Specialization/5. Reproducible Research/RepData_PeerAssessment1")
cat(paste(system("7za l activity.zip", intern = TRUE), "\n"))

# Load the data.table package
library(data.table)

# Read the data into a data.table with default fread() options
dt = fread("7za e -so activity.zip activity.csv 2>nul")

# Take a look at the data
str(dt)
dt
```

The instructions indicate that the variable `interval` is the identifier for
5-minute intervals. The first intervals start with the series [0, 5, 10, ...],
and if it were a continuous series during the day, we would expect the
following:

```{r}
# Number of intervals in a day
intervals_per_hour = 60/5
intervals_per_day = 24 * intervals_per_hour

# Sequence of intervals for one day
data.table(seq(from = 0, by = 5, length.out = intervals_per_day))
```

The tail end of the source dataset doesn't match this vector. In fact, it looks
more like the time of the day in 24-hour format, but without the ":" separator.
To confirm this, we can take a quick look at the end of the hour and the end of
the day:

```{r}
# Check out the end of the first hour
dt[(intervals_per_hour - 1):(intervals_per_hour + 2)]

# Check out the 24-hour boundary between the first and second day
dt[(intervals_per_day - 1):(intervals_per_day + 2)]
```

It looks like the `interval` column is actually the time of the day, but it is
formatted as a number: e.g. `55` is followed by `100`; `2355` is followed by
`0`, etc. In case we need a properly formatted `interval` and a proper date and
time variable in later steps, we will transform them and keep them in a new
Date/Time column.

```{r, message=FALSE}
# Load lubridate package for easy handling of dates/times
library(lubridate)

# Reformat date and time and convert to date/time class
dt[, interval := sub("^(..)", "\\1:", sprintf("%04d", interval))]
dt[, timestamp := ymd_hm(paste(date, interval))]
dt[, date := ymd(date)]
str(dt)
```


## What is mean total number of steps taken per day?

To summarize data by group, we can use the `aggregate()` function from the base
R system, or utilize the modern interfaces provided in `data.table` or `dplyr`
packages. For this assignment, we will use `data.table` interface.

```{r}
# Get the steps by date, ignore missing values
steps_by_date = dt[, .( total_steps = sum(steps, na.rm = TRUE) ), date]

# Load the ggplot2 library
library(ggplot2)

# Plot with ggplot
ggplot(steps_by_date, aes(x = date, y = total_steps)) +
  geom_bar(stat = "identity") +
  xlab("Date") +
  ylab("Steps") +
  ggtitle("Total Number of Steps Taken Each Day")

# mean steps taken
mean_steps = steps_by_date[, mean(total_steps, na.rm = TRUE)]

# median steps taken
median_steps = steps_by_date[, median(total_steps, na.rm = TRUE)]
```

During the study period, after removing the missing data, the mean steps taken
per day was **`r prettyNum(mean_steps, big.mark = ",")`** and the median steps
taken per day was **`r prettyNum(median_steps, big.mark = ",")`**.



## What is the average daily activity pattern?

To show the daily activity pattern, we will plot the average steps taken at
each interval over the duration of the study.

```{r, message=FALSE}
# Average of steps taken by interval over the study period
steps_by_interval = dt[, .(average_steps = sum(steps, na.rm = TRUE)), interval]

# Info on the interval with the max average steps
max_step_index     = steps_by_interval[, which.max(average_steps)]
max_steps          = steps_by_interval[max_step_index, average_steps]
max_steps_interval = steps_by_interval[max_step_index, interval]

# There are too many intervals to be plotted: pick the top of the hour to label
# the tick marks
labels = steps_by_interval[seq(1, length(interval), 12), interval]

# For comma formatted y axis labels
require(scales)

# Line graph of average activity during the day
activity = ggplot(steps_by_interval, aes(x = interval, y = average_steps, group = 1)) +
  geom_line() +
  ggtitle("Average Daily Activity Pattern") +
  xlab("Intervals") +
  ylab("Average Steps Taken") +
  scale_x_discrete(breaks=labels, labels=as.character(labels)) +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x=element_text(angle=90))

# Now, add the info about the max steps to the plot and show it
activity +
  geom_segment(
    linetype = "longdash",
    colour = "blue",
    aes(x = max_step_index, y = -Inf, xend = max_step_index, yend = max_steps)
  ) +
  geom_text(
    x = max_step_index, y = max_steps,
    label = prettyNum(max_steps, big.mark = ","),
    hjust=0, vjust=0
  ) +
  geom_text(
    x = max_step_index, y = 0,
    label = max_steps_interval,
    hjust=0.25, vjust=1.25,
    angle = 90
  )
```

On the average, the maximum number of steps during a 5 minute interval were
**`r prettyNum(max_steps, big.mark = ",")`**, taken at
**`r max_steps_interval`**.



## Imputing missing values

There are a number of cases where there are no observations for an interval or
an entire day (coded as NA). The presence of missing data may introduce bias
into some calculations or summaries of the data. Following code chunk shows the
number of intervals with missing data.

```{r}
# Intervals with missing values
nrow(na.omit(dt, invert = TRUE))
```

Note that having some intervals with missing data may have different
implications than having entire days without data, especially if more of some
specific days had missing data. The following section gives some comparisons.

```{r}
# Days without data
missing_days = dt[, .(nmiss = nrow(na.omit(.SD, invert = TRUE)), weekday =
  wday (date, label = TRUE, abbr = TRUE)), date][nmiss > 0]
missing_days

# Percentage of days with missing data
nrow(missing_days)/uniqueN(dt[, date])*100
```

It looks like whenever there are missing data, an entire day's worth of data
are missing. From the above summary, there doesn't appear to be a pattern to
the days with missing data. One approach to imputing data for these missing
intervals is to assign the average number of steps taken across the entire
span of the study period.

An alternative approach is to get the average of the interval for specific
days of the week: it is likely that a person's daily activity on a weekend day
will be more similar to another weekend day rather than a week day. We can
extend the same logic and assume that the expected activity pattern on a
Monday will be similar to the average of activities across all Mondays; and
the expected activity pattern on a Tuesday will be more like the activity on
other Tuesdays, etc.

```{r, warning = FALSE}
# Calculate average steps by interval, overall
estimates_overall = dt[,
  .(nobs = sum(!is.na(steps)), average_steps = mean(steps, na.rm = TRUE)),
  interval
]
setkey(estimates_overall, interval)

# Calculate average steps by interval, by week day
estimates_weekday = dt[,
  .(nobs = sum(!is.na(steps)), average_steps = mean(steps, na.rm = TRUE)),
  .(weekday = wday(date, label = TRUE, abbr = TRUE), interval)
]
setkey(estimates_weekday, weekday, interval)

# Review if these methods yield very different extimates
comb = rbind(
  estimates_overall[, weekday := "Overall"],
  estimates_weekday
)

# See a comparison of these estimates
ggplot(comb, aes(x = interval, y = average_steps)) +
  facet_grid(weekday ~ .) +
  geom_bar(stat = "identity") +
  xlab("Intervals") +
  ylab("Average Steps Taken") +
  scale_x_discrete(breaks=labels, labels=as.character(labels)) + theme(axis.text.x=element_text(angle=90))
```

It is clear from these plots that applying week-day-specific averages will give
us better estimates to impute the missing data points.

```{r, warning = FALSE}
# To compare the alternative estimation methods, create two imputed variables
dt[is.na(steps),
  `:=`(
    imputed_steps_weekday = estimates_weekday[
      .SD[, .(weekday = wday(date, label = TRUE, abbr = TRUE), interval)],
      average_steps
    ], 
    imputed_steps_overall = estimates_overall[
      .SD[, interval],
      average_steps
    ]
  )
]
dt[!is.na(steps), c("imputed_steps_weekday", "imputed_steps_overall") := steps]

# Summarize
steps_by_date_new = rbind(
  dt[, .(type = "Original (na.rm)", total_steps = sum(steps, na.rm = TRUE)), date],
  dt[, .(type = "Impute-Overall",   total_steps = sum(imputed_steps_overall)), date],
  dt[, .(type = "Impute-Weekday",   total_steps = sum(imputed_steps_weekday)), date]
)

# Plot this, show both the original and the imputed variables
ggplot(steps_by_date_new, aes(x = date, y = total_steps, fill = type)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  xlab("Date") +
  ylab("Steps")

# mean steps taken - comparison
steps_by_date_new[, .(mean = mean(total_steps), median = median(total_steps)), type]
```

As we can see from the above results, both the mean and the median are higher
after the missing data were replaced with imputed values. We can also observe
a difference between the two methods of imputing missing values: using the
week-day-specific interval averages as the estimates results in higher updated
mean and median total steps taken per day compared to the estimates based on
overall interval averages: this is because the weekend activity is lower
compared to the week day activity, and there are more week days with missing
data compared to weekend days (see the next section).


## Are there differences in activity patterns between weekdays and weekends?
